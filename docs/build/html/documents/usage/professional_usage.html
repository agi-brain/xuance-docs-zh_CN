<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>专业教程 &mdash; 玄策 v0.1.11 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/fonts.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="configs" href="../api/configs.html" />
    <link rel="prev" title="快速开始" href="basic_usage.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> 玄策
            <img src="../../_static/logo_2.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">如何使用:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">安装教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_usage.html">快速开始</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">专业教程</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#yaml">步骤1：准备YAML文件，配置参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">步骤2：读取参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="#run">步骤3：定义run()，创建模型，运行算法</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API介绍:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/configs.html">configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/common.html">common</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/environments.html">环境封装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/representations.html">状态表征</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/policies.html">状态表征</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/agents.html">Agent类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/learners.html">学习器Learner类</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">算法介绍:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../agents/index_drl.html">深度强化学习(单智能体)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agents/index_marl.html">多智能体强化学习</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">参考基准</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/toy.html">Toy运行结果</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/mujoco.html">MuJoCo运行结果</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/atari.html">Atari运行结果</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/mpe.html">MPE运行结果</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/magent.html">Magent运行结果</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">玄策</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">专业教程</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/documents/usage/professional_usage.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>专业教程<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>上一页是通过调用runner来直接运行算法。为了更好地帮助用户理解“玄策”的内部实现流程，
从而便于进一步做算法开发和实现用户自己的强化学习任务，下面以PPO算法训练MuJoCo环境任务为例，
详细介绍如何从底层地调用API实现强化学习模型训练。</p>
<br><hr><section id="yaml">
<h2>步骤1：准备YAML文件，配置参数<a class="headerlink" href="#yaml" title="Permalink to this headline">¶</a></h2>
<p>创建 <cite>mujoco.yaml</cite> 文件，并指定相关参数，如下所示：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dl_toolbox</span><span class="p">:</span> <span class="s2">&quot;torch&quot;</span>  <span class="c1"># The deep learning toolbox. Choices: &quot;torch&quot;, &quot;mindspore&quot;, &quot;tensorlayer&quot;</span>
<span class="n">project_name</span><span class="p">:</span> <span class="s2">&quot;XuanPolicy_Benchmark&quot;</span>
<span class="n">logger</span><span class="p">:</span> <span class="s2">&quot;tensorboard&quot;</span>  <span class="c1"># Choices: tensorboard, wandb.</span>
<span class="n">wandb_user_name</span><span class="p">:</span> <span class="s2">&quot;your_user_name&quot;</span>
<span class="n">render</span><span class="p">:</span> <span class="kc">False</span>
<span class="n">render_mode</span><span class="p">:</span> <span class="s1">&#39;rgb_array&#39;</span> <span class="c1"># Choices: &#39;human&#39;, &#39;rgb_array&#39;.</span>
<span class="n">test_mode</span><span class="p">:</span> <span class="kc">False</span>
<span class="n">device</span><span class="p">:</span> <span class="s2">&quot;cuda:0&quot;</span>

<span class="n">agent</span><span class="p">:</span> <span class="s2">&quot;PPO_Clip&quot;</span>  <span class="c1"># choice: PPO_Clip, PPO_KL</span>
<span class="n">env_name</span><span class="p">:</span> <span class="s2">&quot;MuJoCo&quot;</span>
<span class="n">vectorize</span><span class="p">:</span> <span class="s2">&quot;Dummy_Gym&quot;</span>
<span class="n">runner</span><span class="p">:</span> <span class="s2">&quot;DRL&quot;</span>

<span class="n">representation_hidden_size</span><span class="p">:</span> <span class="p">[</span><span class="mi">256</span><span class="p">,]</span>
<span class="n">actor_hidden_size</span><span class="p">:</span> <span class="p">[</span><span class="mi">256</span><span class="p">,]</span>
<span class="n">critic_hidden_size</span><span class="p">:</span> <span class="p">[</span><span class="mi">256</span><span class="p">,]</span>
<span class="n">activation</span><span class="p">:</span> <span class="s2">&quot;LeakyReLU&quot;</span>

<span class="n">seed</span><span class="p">:</span> <span class="mi">79811</span>
<span class="n">parallels</span><span class="p">:</span> <span class="mi">16</span>
<span class="n">running_steps</span><span class="p">:</span> <span class="mi">1000000</span>
<span class="n">n_steps</span><span class="p">:</span> <span class="mi">256</span>
<span class="n">n_epoch</span><span class="p">:</span> <span class="mi">16</span>
<span class="n">n_minibatch</span><span class="p">:</span> <span class="mi">8</span>
<span class="n">learning_rate</span><span class="p">:</span> <span class="mf">0.0004</span>

<span class="n">use_grad_clip</span><span class="p">:</span> <span class="kc">True</span>

<span class="n">vf_coef</span><span class="p">:</span> <span class="mf">0.25</span>
<span class="n">ent_coef</span><span class="p">:</span> <span class="mf">0.0</span>
<span class="n">target_kl</span><span class="p">:</span> <span class="mf">0.001</span>  <span class="c1"># for PPO_KL agent</span>
<span class="n">clip_range</span><span class="p">:</span> <span class="mf">0.2</span>  <span class="c1"># for PPO_Clip agent</span>
<span class="n">clip_grad_norm</span><span class="p">:</span> <span class="mf">0.5</span>
<span class="n">gamma</span><span class="p">:</span> <span class="mf">0.99</span>
<span class="n">use_gae</span><span class="p">:</span> <span class="kc">True</span>
<span class="n">gae_lambda</span><span class="p">:</span> <span class="mf">0.95</span>
<span class="n">use_advnorm</span><span class="p">:</span> <span class="kc">True</span>

<span class="n">use_obsnorm</span><span class="p">:</span> <span class="kc">True</span>
<span class="n">use_rewnorm</span><span class="p">:</span> <span class="kc">True</span>
<span class="n">obsnorm_range</span><span class="p">:</span> <span class="mi">5</span>
<span class="n">rewnorm_range</span><span class="p">:</span> <span class="mi">5</span>

<span class="n">test_steps</span><span class="p">:</span> <span class="mi">10000</span>
<span class="n">eval_interval</span><span class="p">:</span> <span class="mi">5000</span>
<span class="n">test_episode</span><span class="p">:</span> <span class="mi">5</span>
<span class="n">log_dir</span><span class="p">:</span> <span class="s2">&quot;./logs/ppo/&quot;</span>
<span class="n">model_dir</span><span class="p">:</span> <span class="s2">&quot;./models/ppo/&quot;</span>
</pre></div>
</div>
<br><hr></section>
<section id="id2">
<h2>步骤2：读取参数<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>该部分主要包括参数读取、环境创建、模型创建、模型训练等环节，分为如下步骤：</p>
<p><strong>步骤2.1 解析终端命令参数</strong></p>
<p>定义如下函数 <code class="docutils literal notranslate"><span class="pre">parse_args()</span></code>，利用Python包 <cite>argparser</cite> 读取终端指令，获取指令参数。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">argparser</span>

<span class="k">def</span> <span class="nf">parse_args</span><span class="p">():</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="s2">&quot;Example of XuanPolicy.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--method&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;ppo&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--env&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;mujoco&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--env-id&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;InvertedPendulum-v4&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--test&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--device&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--benchmark&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--config&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;./ppo_mujoco_config.yaml&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>步骤2.2 读取参数</strong></p>
<p>首先通过调用步骤2.1中的 <code class="docutils literal notranslate"><span class="pre">parse_args()</span></code> 函数读取终端指令参数，然后获取步骤1中的配置参数。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xuanpolicy</span> <span class="kn">import</span> <span class="n">get_arguments</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">()</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">get_arguments</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">parser</span><span class="o">.</span><span class="n">method</span><span class="p">,</span>
                     <span class="n">env</span><span class="o">=</span><span class="n">parser</span><span class="o">.</span><span class="n">env</span><span class="p">,</span>
                     <span class="n">env_id</span><span class="o">=</span><span class="n">parser</span><span class="o">.</span><span class="n">env_id</span><span class="p">,</span>
                     <span class="n">config_path</span><span class="o">=</span><span class="n">parser</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                     <span class="n">parser_args</span><span class="o">=</span><span class="n">parser</span><span class="p">)</span>
<span class="n">run</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</pre></div>
</div>
<p>在该步骤中，调用了“玄策”中的 <code class="docutils literal notranslate"><span class="pre">get_arguments()</span></code> 函数。在该函数中，首先根据 <code class="docutils literal notranslate"><span class="pre">env</span></code> 和 <code class="docutils literal notranslate"><span class="pre">env_id</span></code> 变量组合，从xuanpolicy/configs/路径中查询是否有可读取的参数。
如已经有默认的参数，则全部读取。接着继续从 <code class="docutils literal notranslate"><span class="pre">config.path</span></code> 路径下索引步骤1中的配置文件，并读取.yaml文件中的所有参数。最后读取 <code class="docutils literal notranslate"><span class="pre">parser</span></code> 中的全部参数。
三次读取中，若遇到相同变量名，则以后者参数为准进行更新。最终， <code class="docutils literal notranslate"><span class="pre">get_arguments()</span></code> 函数将返回 <code class="docutils literal notranslate"><span class="pre">args</span></code> 变量，包含所有参数信息，输入 <code class="docutils literal notranslate"><span class="pre">run()</span></code> 函数中。</p>
<br><hr></section>
<section id="run">
<h2>步骤3：定义run()，创建模型，运行算法<a class="headerlink" href="#run" title="Permalink to this headline">¶</a></h2>
<p>定义 <code class="docutils literal notranslate"><span class="pre">run()</span></code> 函数，输入为步骤2中得到的 <code class="docutils literal notranslate"><span class="pre">args</span></code> 变量。在函数中，实现了环境创建，实例化representation、policy、agent等模块，并实现训练。
以下是带注释的run()函数定义示例：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch.optim</span>

<span class="kn">from</span> <span class="nn">xuanpolicy.common</span> <span class="kn">import</span> <span class="n">space2shape</span>
<span class="kn">from</span> <span class="nn">xuanpolicy.environment</span> <span class="kn">import</span> <span class="n">make_envs</span>
<span class="kn">from</span> <span class="nn">xuanpolicy.torch.utils.operations</span> <span class="kn">import</span> <span class="n">set_seed</span>
<span class="kn">from</span> <span class="nn">xuanpolicy.torch.utils</span> <span class="kn">import</span> <span class="n">ActivationFunctions</span>

<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">agent_name</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">agent</span>  <span class="c1"># 获取智能体名称</span>
    <span class="n">set_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># 设置随机种子</span>

    <span class="c1"># prepare directories for results</span>
    <span class="n">args</span><span class="o">.</span><span class="n">model_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">args</span><span class="o">.</span><span class="n">model_dir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">env_id</span><span class="p">)</span>  <span class="c1"># 模型存储/读取路径</span>
    <span class="n">args</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">env_id</span><span class="p">)</span>  <span class="c1"># 日志文件存储路径</span>

    <span class="c1"># build environments</span>
    <span class="n">envs</span> <span class="o">=</span> <span class="n">make_envs</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>  <span class="c1"># 创建强化学习环境</span>
    <span class="n">args</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">observation_space</span>  <span class="c1"># 获取观测空间</span>
    <span class="n">args</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">action_space</span>  <span class="c1"># 获取动作空间</span>
    <span class="n">n_envs</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">num_envs</span>  <span class="c1"># 获取并行环境个数</span>

    <span class="c1"># prepare representation</span>
    <span class="kn">from</span> <span class="nn">xuanpolicy.torch.representations</span> <span class="kn">import</span> <span class="n">Basic_MLP</span>  <span class="c1"># 导入表征器类</span>
    <span class="n">representation</span> <span class="o">=</span> <span class="n">Basic_MLP</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">space2shape</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">observation_space</span><span class="p">),</span>
                            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">representation_hidden_size</span><span class="p">,</span>
                            <span class="n">normalize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">initialize</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">,</span>
                            <span class="n">activation</span><span class="o">=</span><span class="n">ActivationFunctions</span><span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">activation</span><span class="p">],</span>
                            <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># 创建MLP表征器</span>

    <span class="c1"># prepare policy</span>
    <span class="kn">from</span> <span class="nn">xuanpolicy.torch.policies</span> <span class="kn">import</span> <span class="n">Gaussian_AC_Policy</span>  <span class="c1"># 导入策略类</span>
    <span class="n">policy</span> <span class="o">=</span> <span class="n">Gaussian_AC_Policy</span><span class="p">(</span><span class="n">action_space</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
                                <span class="n">representation</span><span class="o">=</span><span class="n">representation</span><span class="p">,</span>
                                <span class="n">actor_hidden_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">actor_hidden_size</span><span class="p">,</span>
                                <span class="n">critic_hidden_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">critic_hidden_size</span><span class="p">,</span>
                                <span class="n">normalize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">initialize</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">,</span>
                                <span class="n">activation</span><span class="o">=</span><span class="n">ActivationFunctions</span><span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">activation</span><span class="p">],</span>
                                <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># 创建服从高斯分布的随机策略</span>

    <span class="c1"># prepare agent</span>
    <span class="kn">from</span> <span class="nn">xuanpolicy.torch.agents</span> <span class="kn">import</span> <span class="n">PPOCLIP_Agent</span><span class="p">,</span> <span class="n">get_total_iters</span>  <span class="c1"># 导入智能体类</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">policy</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>  <span class="c1"># 创建优化器</span>
    <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LinearLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">start_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">end_factor</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                                    <span class="n">total_iters</span><span class="o">=</span><span class="n">get_total_iters</span><span class="p">(</span><span class="n">agent_name</span><span class="p">,</span> <span class="n">args</span><span class="p">))</span>  <span class="c1"># 创建学习率衰减器</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">PPOCLIP_Agent</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
                          <span class="n">envs</span><span class="o">=</span><span class="n">envs</span><span class="p">,</span>
                          <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span>
                          <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                          <span class="n">scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
                          <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># 创建PPO智能体</span>

    <span class="c1"># start running</span>
    <span class="n">envs</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>  <span class="c1"># 环境初始化</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">benchmark</span><span class="p">:</span>  <span class="c1"># run benchmark</span>
        <span class="k">def</span> <span class="nf">env_fn</span><span class="p">():</span>  <span class="c1"># 创建测试环境，用于每个阶段训练结束后，随机初始化测试环境并进行测试</span>
            <span class="n">args_test</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>  <span class="c1"># 拷贝原有参数</span>
            <span class="n">args_test</span><span class="o">.</span><span class="n">parallels</span> <span class="o">=</span> <span class="n">args_test</span><span class="o">.</span><span class="n">test_episode</span>  <span class="c1"># 更改并行环境数量为测试回合数</span>
            <span class="k">return</span> <span class="n">make_envs</span><span class="p">(</span><span class="n">args_test</span><span class="p">)</span>  <span class="c1"># 返回实例化测试环境</span>

        <span class="n">train_steps</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">running_steps</span> <span class="o">//</span> <span class="n">n_envs</span>  <span class="c1"># 获取智能体总的运行步数</span>
        <span class="n">eval_interval</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">eval_interval</span> <span class="o">//</span> <span class="n">n_envs</span>  <span class="c1"># 确定每轮训练步数</span>
        <span class="n">test_episode</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">test_episode</span>  <span class="c1"># 获取测试回合数</span>
        <span class="n">num_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_steps</span> <span class="o">/</span> <span class="n">eval_interval</span><span class="p">)</span>  <span class="c1"># 确定训练轮数</span>

        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env_fn</span><span class="p">,</span> <span class="n">test_episode</span><span class="p">)</span>  <span class="c1"># 第0步测试，得到测试结果</span>
        <span class="n">best_scores_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">),</span>  <span class="c1"># 平均累积回合奖励</span>
                            <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">),</span>  <span class="c1"># 累积回合奖励方差</span>
                            <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">current_step</span><span class="p">}</span>  <span class="c1"># 当前步数</span>
        <span class="k">for</span> <span class="n">i_epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epoch</span><span class="p">):</span>  <span class="c1"># 开始轮回训练</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch: </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2">:&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i_epoch</span><span class="p">,</span> <span class="n">num_epoch</span><span class="p">))</span>  <span class="c1"># 打印第i_epoch轮训练的基本信息</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">eval_interval</span><span class="p">)</span>  <span class="c1"># 训练eval_interval步</span>
            <span class="n">test_scores</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env_fn</span><span class="p">,</span> <span class="n">test_episode</span><span class="p">)</span>  <span class="c1"># 测试test_episode个回合</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">best_scores_info</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">]:</span>  <span class="c1"># 若当前测试结果为历史最高，则保存模型</span>
                <span class="n">best_scores_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">),</span>
                                    <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">),</span>
                                    <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="n">agent</span><span class="o">.</span><span class="n">current_step</span><span class="p">}</span>
                <span class="c1"># save best model</span>
                <span class="n">agent</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;best_model.pth&quot;</span><span class="p">)</span>
        <span class="c1"># end benchmarking</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Model Score: </span><span class="si">%.2f</span><span class="s2">, std=</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">best_scores_info</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span> <span class="n">best_scores_info</span><span class="p">[</span><span class="s2">&quot;std&quot;</span><span class="p">]))</span>  <span class="c1"># 结束benchmark训练，打印最终结果</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">test</span><span class="p">:</span>  <span class="c1"># train the model without testing</span>
            <span class="n">n_train_steps</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">running_steps</span> <span class="o">//</span> <span class="n">n_envs</span>  <span class="c1"># 确定总的运行步数</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">n_train_steps</span><span class="p">)</span>  <span class="c1"># 直接训练模型</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">&quot;final_train_model.pth&quot;</span><span class="p">)</span>  <span class="c1"># 保存最终训练结果</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Finish training!&quot;</span><span class="p">)</span>  <span class="c1"># 结束训练</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># test a trained model</span>
            <span class="k">def</span> <span class="nf">env_fn</span><span class="p">():</span>
                <span class="n">args_test</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="n">args_test</span><span class="o">.</span><span class="n">parallels</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">return</span> <span class="n">make_envs</span><span class="p">(</span><span class="n">args_test</span><span class="p">)</span>

            <span class="n">agent</span><span class="o">.</span><span class="n">render</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">model_dir_load</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># 加载模型文件</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">env_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">test_episode</span><span class="p">)</span>  <span class="c1"># 测试模型</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean Score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="si">}</span><span class="s2">, Std: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Finish testing.&quot;</span><span class="p">)</span>  <span class="c1"># 结束测试</span>

    <span class="c1"># the end.</span>
    <span class="n">envs</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>  <span class="c1"># 关闭环境</span>
    <span class="n">agent</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>  <span class="c1"># 结束实验</span>
</pre></div>
</div>
<p>该部分完整代码见如下链接：</p>
<p><a class="reference external" href="https://github.com/agi-brain/xuanpolicy/examples/ppo/ppo_mujoco.py/">https://github.com/agi-brain/xuanpolicy/examples/ppo/ppo_mujoco.py</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="basic_usage.html" class="btn btn-neutral float-left" title="快速开始" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../api/configs.html" class="btn btn-neutral float-right" title="configs" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, XuanPolicy contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>